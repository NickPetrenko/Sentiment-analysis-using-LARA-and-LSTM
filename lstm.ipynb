{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cf7d1744-cd35-41b5-93e5-0af77980a12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "import math\n",
    "import os\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2ae3a858-be20-4178-931f-ff0e50ce58d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('train_data.csv')\n",
    "valid_data = pd.read_csv('valid_data.csv')\n",
    "test_data = pd.read_csv('test_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "15258fc5-0276-472f-a801-4122f224214f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'story man unnatural feeling pig start opening scene terrific example absurd comedy formal orchestra audience turned insane violent mob crazy chanting singer unfortunately stay absurd whole time general narrative eventually making putting even era turned cryptic dialogue would make shakespeare seem easy third grader technical level better might think good cinematography future great vilmos zsigmond future star sally kirkland frederic forrest seen briefly '"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['Comment'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "47071376-7476-4e8b-bbc6-172e39e66dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_stats(dataframe):\n",
    "    \n",
    "    s = 0.0\n",
    "    pos = 0\n",
    "    \n",
    "    for i in dataframe['Comment']:\n",
    "        word_list = i.split()\n",
    "        s = s + len(word_list)\n",
    "    print(\"Total revievs: \", dataframe.shape[0])\n",
    "    print(\"Average length of each review : \",s/train_data.shape[0])\n",
    "    \n",
    "    try:\n",
    "        for i in range(dataframe.shape[0]):\n",
    "            if dataframe.iloc[i]['Sentiment'] == 1:\n",
    "                pos = pos + 1\n",
    "        neg = dataframe.shape[0] - pos\n",
    "        print(\"Percentage of reviews with positive sentiment: \"+str(pos/dataframe.shape[0]*100)+\"%\")\n",
    "        print(\"Percentage of reviews with negative sentiment: \"+str(neg/dataframe.shape[0]*100)+\"%\")\n",
    "        \n",
    "    except:\n",
    "        print(\"No sentiment in test data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "440d4bfd-85bc-4f37-a78e-39d77caded29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total revievs:  24994\n",
      "Average length of each review :  122.99143794510682\n",
      "Percentage of reviews with positive sentiment: 50.0%\n",
      "Percentage of reviews with negative sentiment: 50.0%\n"
     ]
    }
   ],
   "source": [
    "data_stats(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "21a13e8a-271d-4b74-bda5-ebddf1af892e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total revievs:  24993\n",
      "Average length of each review :  120.19284628310794\n",
      "Percentage of reviews with positive sentiment: 50.00600168047053%\n",
      "Percentage of reviews with negative sentiment: 49.99399831952947%\n"
     ]
    }
   ],
   "source": [
    "data_stats(valid_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e5a4f8f9-93f5-44df-8903-2a0a7d84ce02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total revievs:  49995\n",
      "Average length of each review :  247.2188125150036\n",
      "No sentiment in test data\n"
     ]
    }
   ],
   "source": [
    "data_stats(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1ff26b80-4193-4fa1-bd6d-4be25822ed51",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_data['Comment']\n",
    "X_valid = valid_data['Comment']\n",
    "X_test = test_data['Comment']\n",
    "\n",
    "# y_train = train_data['Sentiment']\n",
    "# y_valid = valid_data['Sentiment']\n",
    "\n",
    "y_train = train_data['Rating']\n",
    "y_valid = valid_data['Rating']\n",
    "\n",
    "num_classes = 11 #amount of numbers from 0 to 9\n",
    "\n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
    "y_valid = tf.keras.utils.to_categorical(y_valid, num_classes)\n",
    "# y_test = tf.keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d7c8ab33-a4dd-4a3e-a687-e8ceed68a246",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b0960fb8-4286-4e50-b459-ce855394fa04",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 1000 # choose based on statistics\n",
    "oov_tok = ''\n",
    "embedding_dim = 128\n",
    "max_length = 300 # choose based on statistics, for example 150 to 200\n",
    "padding_type='post'\n",
    "trunc_type='post'\n",
    "# tokenize sentences\n",
    "tokenizer = Tokenizer(num_words = vocab_size, oov_token=oov_tok)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "word_index = tokenizer.word_index\n",
    "# convert train dataset to sequence and pad sequences\n",
    "train_sequences = tokenizer.texts_to_sequences(X_train)\n",
    "train_padded = pad_sequences(train_sequences, padding='post', maxlen=max_length)\n",
    "# convert Test dataset to sequence and pad sequences\n",
    "valid_sequences = tokenizer.texts_to_sequences(X_valid)\n",
    "valid_padded = pad_sequences(valid_sequences, padding='post', maxlen=max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cb730cf1-00e8-4ccf-80e5-7bd87495a0ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 300, 128)          128000    \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 64)                49408     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 11)                363       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 179,851\n",
      "Trainable params: 179,851\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
    "    # keras.layers.Bidirectional(keras.layers.LSTM(64, return_sequences=True)),\n",
    "    keras.layers.LSTM(64),\n",
    "    keras.layers.Dense(32, activation='relu'),\n",
    "    keras.layers.Dense(11, activation='sigmoid')\n",
    "])\n",
    "# compile model\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate = 0.001)\n",
    "model.compile(loss = tf.keras.losses.CategoricalCrossentropy(),\n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy'])\n",
    "# model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d9f33e6f-271e-4ce8-ae05-6e58331ab5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tb_callback = tf.keras.callbacks.TensorBoard(log_dir=\"logs/\", histogram_freq=1)\n",
    "\n",
    "checkpoint_path = \"training/cp-{epoch:04d}.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath = checkpoint_path, save_weights_only=True, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "af2b1288-94a0-479f-b7f7-313eeb332efd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "782/782 [==============================] - ETA: 0s - loss: 2.0494 - accuracy: 0.2001\n",
      "Epoch 1: saving model to training\\cp-0001.ckpt\n",
      "782/782 [==============================] - 94s 119ms/step - loss: 2.0494 - accuracy: 0.2001 - val_loss: 2.0271 - val_accuracy: 0.2029\n",
      "Epoch 2/5\n",
      "782/782 [==============================] - ETA: 0s - loss: 2.0280 - accuracy: 0.2029\n",
      "Epoch 2: saving model to training\\cp-0002.ckpt\n",
      "782/782 [==============================] - 93s 119ms/step - loss: 2.0280 - accuracy: 0.2029 - val_loss: 2.0238 - val_accuracy: 0.2008\n",
      "Epoch 3/5\n",
      "782/782 [==============================] - ETA: 0s - loss: 2.0205 - accuracy: 0.2097\n",
      "Epoch 3: saving model to training\\cp-0003.ckpt\n",
      "782/782 [==============================] - 93s 118ms/step - loss: 2.0205 - accuracy: 0.2097 - val_loss: 2.0238 - val_accuracy: 0.2038\n",
      "Epoch 4/5\n",
      "782/782 [==============================] - ETA: 0s - loss: 2.0112 - accuracy: 0.2150\n",
      "Epoch 4: saving model to training\\cp-0004.ckpt\n",
      "782/782 [==============================] - 93s 119ms/step - loss: 2.0112 - accuracy: 0.2150 - val_loss: 2.0373 - val_accuracy: 0.2047\n",
      "Epoch 5/5\n",
      "782/782 [==============================] - ETA: 0s - loss: 1.9995 - accuracy: 0.2191\n",
      "Epoch 5: saving model to training\\cp-0005.ckpt\n",
      "782/782 [==============================] - 94s 120ms/step - loss: 1.9995 - accuracy: 0.2191 - val_loss: 2.0279 - val_accuracy: 0.2044\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 5\n",
    "history = model.fit(train_padded, y_train, \n",
    "                    epochs=num_epochs, verbose=1, callbacks = [tb_callback, cp_callback],\n",
    "                   validation_data = (valid_padded, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e36118c0-e4fb-4433-bf59-11870ae45a06",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 25s 32ms/step\n",
      "Accuracy of validation on test set :  0.20441723682631135\n"
     ]
    }
   ],
   "source": [
    "prediction = model.predict(valid_padded)\n",
    "# print(prediction)\n",
    "# # Get labels based on probability 1 if p>= 0.5 else 0\n",
    "# pred_labels = []\n",
    "for i in range(len(prediction)):\n",
    "    prediction[i] = np.where(prediction[i] < max(prediction[i]), 0, 1)\n",
    "print(\"Accuracy of validation on test set : \", accuracy_score(y_valid,prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dcca333d-0ac7-41e6-a0f6-633d01d7b49b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fdcb01a6-b361-4d36-912b-37c0507225a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ca3dbe-c4d2-41eb-92b3-565142618575",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e20768c-80f2-4fef-a8db-ab8cf6979aba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
